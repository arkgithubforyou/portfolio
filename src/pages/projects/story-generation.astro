---
import ProjectLayout from '../../layouts/ProjectLayout.astro';

const project = {
  title: "Controlled Story Generation",
  description: "Multi-task neural architecture for controlled text generation with rich details.",
  tags: ["PyTorch", "Text Generation", "Attention", "Crowdsourcing"],
};

const baseUrl = import.meta.env.BASE_URL;
---

<ProjectLayout {...project}>
  <p>
    <a href="https://aclanthology.org/2020.coling-main.212/" target="_blank" rel="noopener noreferrer">Published at COLING 2020</a>
  </p>

  <img src={`${baseUrl}images/story0.png`} alt="Story Generation Architecture" />

  <h2>Overview</h2>
  <p>
    Automatically generated text should be both coherent and engaging, but most language models face a fundamental trade-off: they either produce generic, boring content or lose coherence when trying to add detail. This project solved this problem by developing a production-ready neural architecture that generates engaging, detailed narratives while maintaining global coherence.
  </p>

  <h2>Impact</h2>
  <ul>
    <li><strong>34% improvement</strong> in content informativeness over state-of-the-art baseline</li>
    <li><strong>90% data reduction</strong> through strategic use of pre-trained embeddings</li>
    <li>Maintained global coherence (0.49 vs 0.40 baseline)</li>
    <li>Production speed: 8 tokens/second on single GPU</li>
    <li>Results validated through rigorous human evaluation (200 stories, 1,221 ratings)</li>
  </ul>

  <h2>Technical Approach</h2>
  <p>The system uses a multi-task learning framework with three key components:</p>
  <ul>
    <li><strong>Agenda-aware encoder:</strong> Bi-LSTM that tracks generation progress through the planned narrative structure</li>
    <li><strong>Dual decoders:</strong> Separate decoders for structural content (main events) and enrichment content (engaging details)</li>
    <li><strong>Maximum Mutual Information objective:</strong> Anti-generic decoding that penalizes common phrases and promotes specific, contextually relevant content</li>
  </ul>

  <h2>Key Challenges Solved</h2>
  <h3>Evaluating Generated Story Quality</h3>
  <p>
    Standard metrics like BLEU correlate poorly with human judgments of narrative quality. We designed a comprehensive human evaluation schema across multiple dimensions, implemented via LingoTurk on Prolific with 10 native speakers rating each story.
  </p>

  <h3>Reducing Generic Text Generation</h3>
  <p>Neural language models tend to produce generic, high-probability text. We implemented MMI decoding that actively suppresses high-frequency generic phrases:</p>
  <pre><code>score = log p(text|context) - 0.1 Ã— log p(text)</code></pre>

  <h2>Results</h2>
  <table>
    <thead>
      <tr>
        <th>Model</th>
        <th>Informativeness</th>
        <th>Global Coherence</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Baseline</td>
        <td>0.38</td>
        <td>0.40</td>
      </tr>
      <tr>
        <td><strong>Our Model</strong></td>
        <td><strong>0.51</strong></td>
        <td><strong>0.49</strong></td>
      </tr>
      <tr>
        <td>Human (upper bound)</td>
        <td>0.66</td>
        <td>0.66</td>
      </tr>
    </tbody>
  </table>
</ProjectLayout>
