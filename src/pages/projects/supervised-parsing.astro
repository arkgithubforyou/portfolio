---
import ProjectLayout from '../../layouts/ProjectLayout.astro';

const project = {
  title: "Supervised Script Parsing",
  description: "Hierarchical sequence modeling for procedural knowledge extraction.",
  tags: ["NLU", "XLNet", "Back-translation", "Sequence Labeling"],
};

const baseUrl = import.meta.env.BASE_URL;
---

<ProjectLayout {...project}>
  <p>
    <a href="https://aclanthology.org/2021.starsem-1.18" target="_blank" rel="noopener noreferrer">Published at *SEM 2021</a>
  </p>

  <img src={`${baseUrl}images/ssp.png`} alt="Supervised Script Parsing Architecture" />

  <h2>Overview</h2>
  <p>
    Understanding how everyday activities unfold is fundamental to many NLP applications, from conversational AI to content generation. Script parsing is the task of automatically identifying which parts of a text correspond to activity-specific events and participants.
  </p>
  <p>
    This task is challenging even for humans (inter-annotator agreement: 0.64-0.77 Fleiss' κ). Previous approaches achieved only 66% accuracy on event parsing and had not successfully addressed participant parsing at all.
  </p>

  <h2>Impact</h2>
  <ul>
    <li><strong>+16.1 F1 points</strong> improvement over previous SOTA in event parsing</li>
    <li><strong>85.7% micro-F1</strong> for event parsing</li>
    <li><strong>90.3% micro-F1</strong> for participant parsing (first successful system)</li>
    <li>Single scenario-agnostic model handles all 10 activity scenarios</li>
  </ul>

  <h2>Technical Approach</h2>
  <p>
    The key insight is that script parsing requires information at two different granularities:
  </p>
  <ul>
    <li><strong>Word-level patterns:</strong> How events are expressed in surface language</li>
    <li><strong>Discourse-level patterns:</strong> The procedural order in which events occur</li>
  </ul>

  <h3>Architecture</h3>
  <p>Two-level sequence modeling:</p>
  <ul>
    <li><strong>Stage 1 - Word sequence model:</strong> XLNet-base-cased encoding of the full story</li>
    <li><strong>Stage 2 - Event sequence model:</strong> Bi-LSTM over extracted candidates, modeling discourse-level patterns</li>
  </ul>

  <h3>Addressing Data Sparsity</h3>
  <p>With 26 classes having fewer than 10 instances:</p>
  <ul>
    <li><strong>Domain adaptation:</strong> Corpus embeddings to handle cross-corpus differences</li>
    <li><strong>Back-translation augmentation:</strong> English → French → English paraphrasing via Google Translate</li>
  </ul>

  <h2>Results</h2>
  <table>
    <thead>
      <tr>
        <th>Model</th>
        <th>Event F1</th>
        <th>Participant F1</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Previous SOTA (CRF)</td>
        <td>58.1 / 66.0</td>
        <td>n/a</td>
      </tr>
      <tr>
        <td>Fine-tuned XLNet</td>
        <td>62.1 / 79.3</td>
        <td>79.7 / 77.2</td>
      </tr>
      <tr>
        <td><strong>Our Full Model</strong></td>
        <td><strong>75.1 / 85.7</strong></td>
        <td><strong>80.3 / 90.3</strong></td>
      </tr>
    </tbody>
  </table>
  <p>Values shown as macro / micro F1</p>

  <h2>Key Findings</h2>
  <p>
    Ablation study removing the event sequence model dropped performance from 70.1 to 63.3 macro-F1, confirming that discourse-level modeling is essential. Error analysis showed 23% of errors were actually annotation errors in the original data.
  </p>
</ProjectLayout>
